{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "load_dotenv()  \n",
    "OPENAI_API_KEY  = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts.dataset_generation import general_Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the JSON file\n",
    "def read_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: the file {file_path} was not found.\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding the JSON: {e}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a CSV file to write the emails\n",
    "with open('dataset.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames, delimiter=';')\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Loop through each prompt\n",
    "    for prompt_info in prompts.get(\"prompts\", []):\n",
    "        prompt_name = prompt_info['name']\n",
    "        prompt_instructions = prompt_info['instructions']\n",
    "        total_emails = prompt_info['emails_to_generate']\n",
    "        emails_generated = 0\n",
    "\n",
    "        print(f\"Generating emails for prompt: {prompt_name}\")\n",
    "\n",
    "        while emails_generated < total_emails:\n",
    "            print(f'Email to generate: {total_emails - emails_generated}')\n",
    "            batch_size = min(12, total_emails - emails_generated)  # Generate up to 12 emails at a time\n",
    "\n",
    "            # Prepare the prompt for the API\n",
    "            api_prompt = f\"\"\"\n",
    "            Generate {batch_size} unique emails, one email for each of the 12 purpose categories. Create the emails in\n",
    "            CSV format. Follow these strict guidelines:\n",
    "\n",
    "            1. Use \";\" as the separator between fields.\n",
    "            2. Enclose all field values in double quotes (e.g., \"value1\";\"value2\";\"value3\").\n",
    "            3. Do not include any introductions, explanations, or formatting like triple backticks (```) in the response.\n",
    "            4. Provide only the raw CSV content with the following fields:\n",
    "            {'; '.join(fieldnames)}\n",
    "\n",
    "            Each email should be unique and adhere to the guidelines provided.\n",
    "\n",
    "\n",
    "\n",
    "            Each email should be unique and adhere to the guidelines.\n",
    "            \"\"\"\n",
    "\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model='gpt-4o-mini',\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": general_Instructions + '\\n' + prompt_instructions},\n",
    "                        {\"role\": \"user\", \"content\": api_prompt}\n",
    "                    ],\n",
    "                    n=1,\n",
    "                    temperature=0.7,\n",
    "                )\n",
    "\n",
    "                # Extract the assistant's reply\n",
    "                assistant_reply = response.choices[0].message.content\n",
    "\n",
    "                # Process the assistant's reply and write to CSV\n",
    "                # Split the response into lines\n",
    "                lines = assistant_reply.strip().split('\\n')\n",
    "\n",
    "                # Skip any empty lines or headers\n",
    "                data_lines = [line for line in lines if line.strip() and not line.startswith(('subject', 'sender'))]\n",
    "\n",
    "                reader = csv.DictReader(data_lines, fieldnames=fieldnames, delimiter=';')\n",
    "                for row in reader:\n",
    "                    writer.writerow(row)\n",
    "\n",
    "                emails_generated += batch_size\n",
    "\n",
    "                # Sleep to respect rate limits\n",
    "                time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                print(\"Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "\n",
    "print(\"Email dataset generation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "# Loop through each prompt\n",
    "for prompt_info in prompts.get(\"prompts\", []):\n",
    "    prompt_name = prompt_info['name']\n",
    "    prompt_instructions = prompt_info['instructions']\n",
    "    total_emails = prompt_info['emails_to_generate']\n",
    "    emails_generated = 0\n",
    "\n",
    "    # Create a filename for each prompt based on its name\n",
    "    sanitized_name = prompt_name.replace(\" \", \"_\").replace(\"/\", \"_\")  # Sanitize name for filename\n",
    "    filename = f\"{sanitized_name}.csv\"\n",
    "\n",
    "    print(f\"Generating emails for prompt: {prompt_name}\")\n",
    "    print(f\"Saving data to file: {filename}\")\n",
    "\n",
    "    # Open a separate CSV file for each prompt\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames, delimiter=';')\n",
    "        writer.writeheader()\n",
    "\n",
    "        while emails_generated < total_emails:\n",
    "            print(f'Emails left to generate: {total_emails - emails_generated}')\n",
    "            batch_size = min(12, total_emails - emails_generated)  # Generate up to 12 emails at a time\n",
    "\n",
    "            # Prepare the prompt for the API\n",
    "            api_prompt = f\"\"\"\n",
    "            Generate {batch_size} unique emails, one email for each of the 12 purpose categories. Create the emails in\n",
    "            CSV format. Follow these strict guidelines:\n",
    "\n",
    "            1. Use \";\" as the separator between fields.\n",
    "            2. Enclose all field values in double quotes (e.g., \"value1\";\"value2\";\"value3\").\n",
    "            3. Do not include any introductions, explanations, or formatting like triple backticks (```) in the response.\n",
    "            4. Provide only the raw CSV content with the following fields:\n",
    "            {'; '.join(fieldnames)}\n",
    "\n",
    "            Each email should be unique and adhere to the guidelines.\n",
    "            \"\"\"\n",
    "\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model='gpt-4o-mini',\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": general_Instructions + '\\n' + prompt_instructions},\n",
    "                        {\"role\": \"user\", \"content\": api_prompt}\n",
    "                    ],\n",
    "                    n=1,\n",
    "                    temperature=0.7,\n",
    "                )\n",
    "\n",
    "                # Extract the assistant's reply\n",
    "                assistant_reply = response.choices[0].message.content\n",
    "\n",
    "                # Process the assistant's reply and write to CSV\n",
    "                # Split the response into lines\n",
    "                lines = assistant_reply.strip().split('\\n')\n",
    "\n",
    "                # Skip any empty lines or headers\n",
    "                data_lines = [line for line in lines if line.strip() and not line.startswith(('subject', 'sender'))]\n",
    "\n",
    "                reader = csv.DictReader(data_lines, fieldnames=fieldnames, delimiter=';')\n",
    "                for row in reader:\n",
    "                    writer.writerow(row)\n",
    "\n",
    "                emails_generated += batch_size\n",
    "\n",
    "                # Sleep to respect rate limits\n",
    "                time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                print(\"Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "\n",
    "    print(f\"Finished generating emails for prompt: {prompt_name}\")\n",
    "\n",
    "print(\"All email datasets generation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "\n",
    "# CSV Fieldnames\n",
    "fieldnames = [\n",
    "    'subject',\n",
    "    'sender',\n",
    "    'recipients',\n",
    "    'body'\n",
    "]\n",
    "\n",
    "# Lock per gestire le scritture concorrenti sul file CSV\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Funzione per generare un batch di email\n",
    "def generate_email_batch(prompt_info, batch_size, fieldnames):\n",
    "    prompt_instructions = prompt_info['instructions']\n",
    "\n",
    "    # Prepare the prompt for the API\n",
    "    api_prompt = f\"\"\"\n",
    "    Generate {batch_size} unique emails, one email for each of the 12 purpose categories. Create the emails in\n",
    "    CSV format. Follow these strict guidelines:\n",
    "\n",
    "    1. Use \";\" as the separator between fields.\n",
    "    2. Enclose all field values in double quotes (e.g., \"value1\";\"value2\";\"value3\").\n",
    "    3. Do not include any introductions, explanations, or formatting like triple backticks (```) in the response.\n",
    "    4. Provide only the raw CSV content with the following fields:\n",
    "    {'; '.join(fieldnames)}\n",
    "\n",
    "    Each email should be unique and adhere to the guidelines provided.\n",
    "\n",
    "\n",
    "\n",
    "    Each email should be unique and adhere to the guidelines.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": general_Instructions + '\\n' + prompt_instructions},\n",
    "                {\"role\": \"user\", \"content\": api_prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        # Estrarre la risposta dell'AI\n",
    "        assistant_reply = response.choices[0].message.content\n",
    "        lines = assistant_reply.strip().split('\\n')\n",
    "\n",
    "        # Filtrare righe non necessarie e processare i dati\n",
    "        data_lines = [line for line in lines if line.strip() and not line.startswith(('subject', 'sender'))]\n",
    "        reader = csv.DictReader(data_lines, fieldnames=fieldnames, delimiter=';')\n",
    "        return list(reader)  # Restituisce un elenco di righe come dizionari\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch generation: {e}\")\n",
    "        return []  # Ritorna una lista vuota in caso di errore\n",
    "\n",
    "# Funzione per gestire i thread\n",
    "def process_prompt(prompt_info, total_emails, csv_writer):\n",
    "    emails_generated = 0\n",
    "    batch_size = 12  # Dimensione del batch\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1000) as executor:  # 5 thread per parallelo\n",
    "        futures = []\n",
    "\n",
    "        # Pianificare i batch di email\n",
    "        while emails_generated < total_emails:\n",
    "            batch_to_generate = min(batch_size, total_emails - emails_generated)\n",
    "            futures.append(\n",
    "                executor.submit(generate_email_batch, prompt_info, batch_to_generate, fieldnames)\n",
    "            )\n",
    "            emails_generated += batch_to_generate\n",
    "\n",
    "        # Scrivere i risultati nel file CSV\n",
    "        for future in futures:\n",
    "            rows = future.result()  # Raccogliere i risultati dal thread\n",
    "            with lock:  # Garantire che solo un thread scriva alla volta\n",
    "                for row in rows:\n",
    "                    # Validare i campi prima di scrivere\n",
    "                    if not row or any(key not in fieldnames for key in row.keys()):\n",
    "                        print(f\"Invalid row detected and skipped: {row}\")\n",
    "                        continue  # Salta le righe non valide\n",
    "                    try:\n",
    "                        csv_writer.writerow(row)\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error writing row: {row}, Error: {e}\")\n",
    "\n",
    "\n",
    "# Scrittura dei dati nel file CSV\n",
    "with open('dataset.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(\n",
    "        csv_file, \n",
    "        fieldnames=fieldnames, \n",
    "        delimiter=';', \n",
    "        quoting=csv.QUOTE_ALL  # Forza l'uso delle virgolette doppie su tutti i valori\n",
    "    )\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Loop attraverso i prompt\n",
    "    for prompt_info in prompts:\n",
    "        prompt_name = prompt_info['name']\n",
    "        total_emails = prompt_info['emails_to_generate']\n",
    "\n",
    "        print(f\"Processing prompt: {prompt_name}\")\n",
    "        process_prompt(prompt_info, total_emails, writer)\n",
    "\n",
    "print(\"Email dataset generation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts.dataset_generation import general_instruction_01 as general_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing prompt: General Dataset\n",
      "Saving data to file: ./datasets/General_Dataset.csv\n",
      "Finished processing prompt: General Dataset\n",
      "\n",
      "Processing prompt: Edge Cases\n",
      "Saving data to file: ./datasets/Edge_Cases.csv\n",
      "Finished processing prompt: Edge Cases\n",
      "\n",
      "Processing prompt: Language and Cultural Diversity\n",
      "Saving data to file: ./datasets/Language_and_Cultural_Diversity.csv\n",
      "Finished processing prompt: Language and Cultural Diversity\n",
      "\n",
      "Processing prompt: Special Service Requests (SSR) Emphasis\n",
      "Saving data to file: ./datasets/Special_Service_Requests_(SSR)_Emphasis.csv\n",
      "Finished processing prompt: Special Service Requests (SSR) Emphasis\n",
      "\n",
      "Processing prompt: High Complexity\n",
      "Saving data to file: ./datasets/High_Complexity.csv\n",
      "Finished processing prompt: High Complexity\n",
      "\n",
      "Processing prompt: Sentiment Variations\n",
      "Saving data to file: ./datasets/Sentiment_Variations.csv\n",
      "Finished processing prompt: Sentiment Variations\n",
      "\n",
      "Processing prompt: Diverse Writing Styles and Formats\n",
      "Saving data to file: ./datasets/Diverse_Writing_Styles_and_Formats.csv\n",
      "Finished processing prompt: Diverse Writing Styles and Formats\n",
      "\n",
      "Processing prompt: Tool Requirement Variations\n",
      "Saving data to file: ./datasets/Tool_Requirement_Variations.csv\n",
      "Finished processing prompt: Tool Requirement Variations\n",
      "\n",
      "Processing prompt: Customer Status Unknown\n",
      "Saving data to file: ./datasets/Customer_Status_Unknown.csv\n",
      "Finished processing prompt: Customer Status Unknown\n",
      "\n",
      "Processing prompt: Urgency and Priority Levels\n",
      "Saving data to file: ./datasets/Urgency_and_Priority_Levels.csv\n",
      "Finished processing prompt: Urgency and Priority Levels\n",
      "Email dataset generation complete.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# CSV Fieldnames\n",
    "fieldnames = [\n",
    "    'subject',\n",
    "    'sender',\n",
    "    'recipients',\n",
    "    'body'\n",
    "]\n",
    "\n",
    "# Reading json file with prompts for dataset generator\n",
    "file_path = './config/prompt_configs.json'  \n",
    "prompts = read_json(file_path)\n",
    "\n",
    "# Lock for managing concurrent writes to the CSV file\n",
    "lock = threading.Lock()\n",
    "\n",
    "def create_enhanced_prompt(general_instructions: str, prompt_info: Dict, batch_size: int, fieldnames: List[str]) -> Dict:\n",
    "    \"\"\"\n",
    "    Creates an enhanced prompt combining general guidelines with specific scenario instructions.\n",
    "    \"\"\"\n",
    "    scenario_name = prompt_info[\"name\"]\n",
    "    scenario_instructions = prompt_info[\"instructions\"]\n",
    "    \n",
    "    system_content = f\"\"\"\n",
    "    {general_instructions}\n",
    "\n",
    "    SPECIFIC SCENARIO FOCUS: {scenario_name}\n",
    "    {scenario_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "    user_content = f\"\"\"\n",
    "    Generate {batch_size} unique emails **one per each purpose categories** following these strict formatting guidelines:\n",
    "\n",
    "    1. Use \";\" as the separator between fields\n",
    "    2. Enclose all field values in double quotes (e.g., \"value1\";\"value2\";\"value3\")\n",
    "    3. Include only the raw CSV content with these fields: {'; '.join(fieldnames)}\n",
    "    4. No explanatory text or formatting markers\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": user_content}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "    }\n",
    "\n",
    "# Function to generate a batch of emails\n",
    "def generate_email_batch(prompt_info, batch_size, fieldnames):\n",
    "    \n",
    "    enhanced_prompt = create_enhanced_prompt(\n",
    "            general_instructions=general_instruction,\n",
    "            prompt_info=prompt_info,\n",
    "            batch_size=batch_size,\n",
    "            fieldnames=fieldnames\n",
    "        )\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Make API call\n",
    "        response = client.chat.completions.create(\n",
    "            model='gpt-4o', \n",
    "            messages=enhanced_prompt[\"messages\"],\n",
    "            temperature=enhanced_prompt[\"temperature\"],\n",
    "        )\n",
    "\n",
    "        # Extract the AI's response\n",
    "        assistant_reply = response.choices[0].message.content\n",
    "        lines = assistant_reply.strip().split('\\n')\n",
    "\n",
    "        # Filter unnecessary lines and process data\n",
    "        data_lines = [\n",
    "            line for line in lines \n",
    "            if line.strip() and not (line.startswith(\"```\") or line.startswith(\"```csv\") or line.startswith('\"subject\"'))\n",
    "        ]\n",
    "        reader = csv.DictReader(data_lines, fieldnames=fieldnames, delimiter=';')\n",
    "        return list(reader)  # Return a list of rows as dictionaries\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch generation: {e}\")\n",
    "        return []  # Return an empty list in case of an error\n",
    "\n",
    "# Function to process a single prompt\n",
    "def process_prompt(prompt_info, total_emails, output_file):\n",
    "    emails_generated = 0\n",
    "    batch_size = 12  # Batch size\n",
    "\n",
    "    # Create a filename for each prompt based on its name\n",
    "    sanitized_name = prompt_info['name'].replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    csv_filename = f\"./datasets/{sanitized_name}.csv\"\n",
    "\n",
    "    print(f\"\\nProcessing prompt: {prompt_info['name']}\")\n",
    "    print(f\"Saving data to file: {csv_filename}\")\n",
    "\n",
    "    # Open a new CSV file for each prompt\n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames, delimiter=';', quoting=csv.QUOTE_ALL)\n",
    "        writer.writeheader()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=1000) as executor:  # Use up to 5 threads for parallelism\n",
    "            futures = []\n",
    "\n",
    "            # Schedule batches of email generation\n",
    "            while emails_generated < total_emails:\n",
    "                batch_to_generate = min(batch_size, total_emails - emails_generated)\n",
    "                futures.append(\n",
    "                    executor.submit(generate_email_batch, prompt_info, batch_to_generate, fieldnames)\n",
    "                )\n",
    "                emails_generated += batch_to_generate\n",
    "\n",
    "            # Write results to the CSV file\n",
    "            for future in futures:\n",
    "                rows = future.result()  # Collect results from the thread\n",
    "                with lock:  # Ensure only one thread writes at a time\n",
    "                    for row in rows:\n",
    "                        # Validate fields before writing\n",
    "                        if not row or any(key not in fieldnames for key in row.keys()):\n",
    "                            print(f\"Invalid row detected and skipped: {row}\")\n",
    "                            continue  # Skip invalid rows\n",
    "                        try:\n",
    "                            writer.writerow(row)\n",
    "                        except ValueError as e:\n",
    "                            print(f\"Error writing row: {row}, Error: {e}\")\n",
    "\n",
    "    print(f\"Finished processing prompt: {prompt_info['name']}\")\n",
    "\n",
    "\n",
    "# Process each prompt\n",
    "for prompt_info in prompts.get(\"prompts\", []):\n",
    "    process_prompt(prompt_info, prompt_info['emails_to_generate'], fieldnames)\n",
    "\n",
    "print(\"Email dataset generation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: ./datasets\\Customer_Status_Unknown.csv\n",
      "Reading file: ./datasets\\Diverse_Writing_Styles_and_Formats.csv\n",
      "Reading file: ./datasets\\Edge_Cases.csv\n",
      "Reading file: ./datasets\\General_Dataset.csv\n",
      "Reading file: ./datasets\\High_Complexity.csv\n",
      "Reading file: ./datasets\\Language_and_Cultural_Diversity.csv\n",
      "Reading file: ./datasets\\Sentiment_Variations.csv\n",
      "Reading file: ./datasets\\Special_Service_Requests_(SSR)_Emphasis.csv\n",
      "Reading file: ./datasets\\Tool_Requirement_Variations.csv\n",
      "Reading file: ./datasets\\Urgency_and_Priority_Levels.csv\n",
      "Combined dataset saved to ./datasets/combined_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path alla directory contenente i CSV\n",
    "directory = './datasets'\n",
    "\n",
    "# Nome del file di output\n",
    "output_file = './datasets/combined_dataset.csv'\n",
    "\n",
    "# Lista per memorizzare i DataFrame\n",
    "dataframes = []\n",
    "\n",
    "# Leggi ogni file CSV nella directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        print(f\"Reading file: {file_path}\")\n",
    "        \n",
    "        # Leggi il file CSV\n",
    "        df = pd.read_csv(file_path, delimiter=';')\n",
    "        \n",
    "        # Aggiungi il DataFrame alla lista\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatena tutti i DataFrame in uno solo\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Rimuovi duplicati di intestazione nel contenuto (se esistono)\n",
    "combined_df = combined_df[~combined_df['subject'].str.contains('subject', na=False)]\n",
    "\n",
    "# Salva il risultato in un unico file CSV\n",
    "combined_df.to_csv(output_file, index=False, sep=';')\n",
    "\n",
    "print(f\"Combined dataset saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
